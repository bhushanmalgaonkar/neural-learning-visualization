{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neural-learning-visualization.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "dtmoS4obWXGF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qLEJLHRjWXGc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TczOSacbWXG3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p0KL554lWXHM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "0245b4fc-bd66-4fda-c67c-ce41cef01764"
      },
      "cell_type": "code",
      "source": [
        "# temporariliy suppress deprecation warnings (https://stackoverflow.com/questions/49901806/tensorflow-importing-mnist-warnings)\n",
        "old_v = tf.logging.get_verbosity()\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "# load mnist data\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
        "\n",
        "# revert logging settings\n",
        "tf.logging.set_verbosity(old_v)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DQKFkPmwWjrc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1a749a94-2a47-478a-e995-84435fb8ea15"
      },
      "cell_type": "code",
      "source": [
        "mnist.train.images.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "owhYYlNiW-cc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Build neural network\n",
        "X = tf.placeholder(dtype='float', shape=[None, 784])\n",
        "y = tf.placeholder(dtype='float', shape=[None, 10])\n",
        "\n",
        "std = 0.05\n",
        "\n",
        "weights = {\n",
        "    'w1': tf.Variable(dtype='float', initial_value=tf.truncated_normal(shape=[784, 1024], mean=0.0, stddev=std)),\n",
        "    'w2': tf.Variable(dtype='float', initial_value=tf.truncated_normal(shape=[1024, 1024], mean=0.0, stddev=std)),\n",
        "    'w3': tf.Variable(dtype='float', initial_value=tf.truncated_normal(shape=[1024, 1024], mean=0.0, stddev=std)),\n",
        "    'w4': tf.Variable(dtype='float', initial_value=tf.truncated_normal(shape=[1024, 1024], mean=0.0, stddev=std)),\n",
        "    'w5': tf.Variable(dtype='float', initial_value=tf.truncated_normal(shape=[1024, 1024], mean=0.0, stddev=std)),\n",
        "    'out': tf.Variable(dtype='float', initial_value=tf.truncated_normal(shape=[1024, 10], mean=0.0, stddev=std)),\n",
        "}\n",
        "\n",
        "biases = {\n",
        "    'b1': tf.Variable(dtype='float', initial_value=tf.truncated_normal(shape=[1024], mean=0.0, stddev=std)),\n",
        "    'b2': tf.Variable(dtype='float', initial_value=tf.truncated_normal(shape=[1024], mean=0.0, stddev=std)),\n",
        "    'b3': tf.Variable(dtype='float', initial_value=tf.truncated_normal(shape=[1024], mean=0.0, stddev=std)),\n",
        "    'b4': tf.Variable(dtype='float', initial_value=tf.truncated_normal(shape=[1024], mean=0.0, stddev=std)),\n",
        "    'b5': tf.Variable(dtype='float', initial_value=tf.truncated_normal(shape=[1024], mean=0.0, stddev=std)),\n",
        "    'out': tf.Variable(dtype='float', initial_value=tf.truncated_normal(shape=[10], mean=0.0, stddev=std))\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aUexXP1cxQut",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "z1 = tf.add(tf.matmul(X, weights['w1']), biases['b1'])\n",
        "a1 = tf.nn.relu(z1)\n",
        "\n",
        "z2 = tf.add(tf.matmul(a1, weights['w2']), biases['b2'])\n",
        "a2 = tf.nn.relu(z2)\n",
        "\n",
        "z3 = tf.add(tf.matmul(a2, weights['w3']), biases['b3'])\n",
        "a3 = tf.nn.relu(z3)\n",
        "\n",
        "z4 = tf.add(tf.matmul(a3, weights['w4']), biases['b4'])\n",
        "a4 = tf.nn.relu(z4)\n",
        "\n",
        "z5 = tf.add(tf.matmul(a4, weights['w5']), biases['b5'])\n",
        "a5 = tf.nn.relu(z5)\n",
        "\n",
        "logits = tf.add(tf.matmul(a5, weights['out']), biases['out'])\n",
        "\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=y))\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
        "\n",
        "train = optimizer.minimize(loss=loss)\n",
        "\n",
        "# calculate accuracy\n",
        "correct = tf.equal(tf.argmax(input=logits, axis=1), tf.argmax(input=y, axis=1))\n",
        "accuracy = tf.reduce_mean(tf.cast(dtype='float', x=correct))\n",
        "\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RQGGt0fz0Uyj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "7934a650-db8a-4120-f727-c736046529f1"
      },
      "cell_type": "code",
      "source": [
        "batch_size = 1000\n",
        "total_samples = mnist.train.images.shape[0]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  for epoch in range(1, 51):\n",
        "    for itr in range(total_samples//batch_size):\n",
        "      batch_x, batch_y = mnist.train.next_batch(batch_size=batch_size)\n",
        "      sess.run(train, feed_dict={X: batch_x, y: batch_y})\n",
        "#       if itr % 10 == 0:\n",
        "#         ls, ac = sess.run([loss, accuracy], feed_dict={X: batch_x, y: batch_y})\n",
        "#         print(f'\\tIteration:{itr}\\t, Loss:{ls:.2f}\\t, Accuracy:{ac:.2f}')\n",
        "    if epoch % 10 == 0:\n",
        "      print(f'Epoch:{epoch}')\n",
        "      ls, ac = sess.run([loss, accuracy], feed_dict={X: batch_x, y: batch_y})\n",
        "      print(f'Train set:\\tLoss:{ls:.2f},\\tAccuracy:{ac:.2f}')\n",
        "      ls, ac = sess.run([loss, accuracy], feed_dict={X: mnist.test.images, y: mnist.test.labels})\n",
        "      print(f'Test set:\\tLoss:{ls:.2f},\\tAccuracy:{ac:.2f}\\n')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:10\n",
            "Train set:\tLoss:0.05,\tAccuracy:0.99\n",
            "Test set:\tLoss:0.12,\tAccuracy:0.97\n",
            "\n",
            "Epoch:20\n",
            "Train set:\tLoss:0.01,\tAccuracy:1.00\n",
            "Test set:\tLoss:0.14,\tAccuracy:0.97\n",
            "\n",
            "Epoch:30\n",
            "Train set:\tLoss:0.00,\tAccuracy:1.00\n",
            "Test set:\tLoss:0.16,\tAccuracy:0.97\n",
            "\n",
            "Epoch:40\n",
            "Train set:\tLoss:0.01,\tAccuracy:1.00\n",
            "Test set:\tLoss:0.18,\tAccuracy:0.97\n",
            "\n",
            "Epoch:50\n",
            "Train set:\tLoss:0.01,\tAccuracy:1.00\n",
            "Test set:\tLoss:0.20,\tAccuracy:0.97\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "B_IO9U-X5DkB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}